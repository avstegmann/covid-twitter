{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Twitter Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from requests_oauthlib import OAuth1Session\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Twitter API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "consumer_key = 'Cd1NbKlV8xMLFQdZcUfh67CKA'\n",
    "consumer_secret = 'M2r3BTi4glHD4QVOH6bqox0jNfnq3GKpl6CI98517B09Srzb1e'\n",
    "access_key = '1219450490-BEuwysgyp8qFk7gNZX9A8DtTbhuIlO33ec1CvcP'\n",
    "access_secret = 'Rg21ZrpZClgzk79ABxAG73nxNlha2e6EoaxPZoUj1X05I'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "\n",
    "    def __init__(self, date, text, id, author):\n",
    "        self.date = date\n",
    "        self.text = text\n",
    "        self.id = id\n",
    "        self.author = author\n",
    "\n",
    "    def dump(self):\n",
    "        return {'date': self.date, 'text': self.text, 'id': self.id, 'author': self.author}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_url(hashtags, tweet_mode_extended=True, lang='en', links=True, retweets=True, replies=True, num=100):\n",
    "    \"\"\"\n",
    "    This function puts together the url that is passed on to the twitter API.\n",
    "    :param hashtags: list of hashtags\n",
    "    :param tweet_mode_extended: If true, the API delivers full texts\n",
    "    :param lang: English is the default language\n",
    "    :param links: tweets with links are not included by default\n",
    "    :param retweets: tweets that are retweets are not included by default\n",
    "    :param replies: tweets that are replies are not included by default\n",
    "    :param num: int, number of tweets queried for\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Standard beginning of url\n",
    "    api_plan_standard = 'https://api.twitter.com/1.1/search/tweets.json?'\n",
    "\n",
    "    # Enable extended tweets\n",
    "    if tweet_mode_extended is True:\n",
    "        tweet_mode = 'tweet_mode=extended&'\n",
    "    else:\n",
    "        tweet_mode = ''\n",
    "\n",
    "    # Build hashtag query\n",
    "    q = 'q='\n",
    "    if len(hashtags) > 1:\n",
    "        q += '%28'\n",
    "    for i in range(0, len(hashtags) - 1):\n",
    "        q += ('%23' + hashtags[i] + '%20OR%20')\n",
    "    q += ('%23' + hashtags[-1])\n",
    "    if len(hashtags) > 1:\n",
    "        q += '%29'\n",
    "\n",
    "    # Exclude links\n",
    "    if links is True:\n",
    "        links = '%20-filter%3Alinks'\n",
    "    else:\n",
    "        links = ''\n",
    "\n",
    "    # Exclude retweets\n",
    "    if retweets is True:\n",
    "        retweets = '%20-filter%3Aretweets'\n",
    "    else:\n",
    "        retweets = ''\n",
    "\n",
    "    # Exclude replies\n",
    "    if replies is True:\n",
    "        replies = '%20-filter%3Areplies'\n",
    "    else:\n",
    "        replies = ''\n",
    "\n",
    "    # assemble URL\n",
    "    url = api_plan_standard + tweet_mode + q + '%20lang%3A' + lang + links + retweets + replies + '&count=' + str(num)\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "URL generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = get_url(['corona', 'covid', 'coronavirus', 'covid19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Session authentifizieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mytwitter = OAuth1Session(consumer_key, consumer_secret, access_key, access_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "File einrichten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = 'tweets.csv'\n",
    "tweet_bag = pd.DataFrame(columns=['date', 'text', 'id', 'author'])\n",
    "tweet_bag.to_csv(file_name, sep='|', mode='a', index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tweets sammeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter = 0\n",
    "while True:\n",
    "    try:\n",
    "        response = mytwitter.get(url)\n",
    "        response_data = json.loads(response.text)\n",
    "        for item in response_data['statuses']:\n",
    "            tweet = Tweet(item['created_at'], item['full_text'].replace('\\n', ' '), item['id'], item['user']['screen_name'])\n",
    "            tweet_bag = tweet_bag.append(tweet.dump(), ignore_index=True)\n",
    "        tweet_bag.to_csv(file_name, sep='|', header=False, mode='a', index=False, encoding='UTF-8')\n",
    "        #print('sleep for 5s') -> not necessary as RaspberryPi takes 1 second to write to the csv file\n",
    "        #time.sleep(5) -> twitter API rate limits allow for continuous request every 5 seconds (of 100 tweets)\n",
    "        print(str(counter+1) + '/10')\n",
    "        counter += 1\n",
    "        if counter == 10:\n",
    "            print('drop dupes')\n",
    "            drop_dupe = pd.read_csv(file_name, sep='|')\n",
    "            drop_dupe = drop_dupe.drop_duplicates()\n",
    "            drop_dupe = drop_dupe.sort_values(by='date')\n",
    "            drop_dupe.to_csv(file_name, sep='|', mode='w', index=False, encoding='UTF-8')\n",
    "            drop_dupe.to_csv('backup14.csv', sep='|', mode='w', index=False, encoding='UTF-8')\n",
    "            counter = 0\n",
    "    except KeyError:\n",
    "        print(time.ctime(time.time()))\n",
    "        print('rate limit: wait for 60s')\n",
    "        time.sleep(60)\n",
    "        counter = 0\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(time.ctime(time.time()))\n",
    "        print('twitter is not responding: wait for 60s')\n",
    "        time.sleep(60)\n",
    "        counter = 0\n",
    "    except:\n",
    "        print(time.ctime(time.time()))\n",
    "        print('other error')\n",
    "        counter = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}